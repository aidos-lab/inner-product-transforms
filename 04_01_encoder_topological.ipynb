{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "from datasets.topological import DataModule, DataModuleConfig\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from models.vae import VanillaVAE\n",
    "from models.vae import BaseModel as BaseVAE\n",
    "from models.encoder import BaseModel as EctEncoder\n",
    "from layers.ect import EctLayer, EctConfig\n",
    "\n",
    "from metrics.metrics import get_mse_metrics\n",
    "from metrics.accuracies import compute_mse_accuracies\n",
    "from metrics.loss import compute_mse_loss_fn\n",
    "from layers.directions import generate_directions\n",
    "\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "config = OmegaConf.load(\"./configs/config_encoder_topological.yaml\")\n",
    "\n",
    "dm = DataModule(DataModuleConfig())\n",
    "\n",
    "print(len(dm.test_ds))\n",
    "\n",
    "# for batch in dm.test_dataloader():\n",
    "#     print(batch.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BaseModel:\n\tMissing key(s) in state_dict: \"model.9.weight\", \"model.9.bias\". \n\tsize mismatch for model.7.weight: copying a param with shape torch.Size([3072, 4096]) from checkpoint, the shape in current model is torch.Size([4096, 4096]).\n\tsize mismatch for model.7.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([4096]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m layer \u001b[38;5;241m=\u001b[39m EctLayer(\n\u001b[0;32m      2\u001b[0m     EctConfig(\n\u001b[0;32m      3\u001b[0m         num_thetas\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mect_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     v\u001b[38;5;241m=\u001b[39mgenerate_directions(config\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mect_size,config\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mdim, DEVICE),\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load the encoder \u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m ect_encoder_litmodel \u001b[38;5;241m=\u001b[39m \u001b[43mEctEncoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./trained_models/ectencoder_topological.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mect_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mect_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_pts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_pts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\utilities\\model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m     )\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\core\\module.py:1581\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1579\u001b[0m \n\u001b[0;32m   1580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1581\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m _load_from_checkpoint(\n\u001b[0;32m   1582\u001b[0m         \u001b[38;5;28mcls\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1583\u001b[0m         checkpoint_path,\n\u001b[0;32m   1584\u001b[0m         map_location,\n\u001b[0;32m   1585\u001b[0m         hparams_file,\n\u001b[0;32m   1586\u001b[0m         strict,\n\u001b[0;32m   1587\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1588\u001b[0m     )\n\u001b[0;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\core\\saving.py:91\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[1;32m---> 91\u001b[0m     model \u001b[38;5;241m=\u001b[39m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, strict\u001b[38;5;241m=\u001b[39mstrict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\core\\saving.py:180\u001b[0m, in \u001b[0;36m_load_state\u001b[1;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[0;32m    177\u001b[0m     obj\u001b[38;5;241m.\u001b[39mon_load_checkpoint(checkpoint)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mmissing_keys:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BaseModel:\n\tMissing key(s) in state_dict: \"model.9.weight\", \"model.9.bias\". \n\tsize mismatch for model.7.weight: copying a param with shape torch.Size([3072, 4096]) from checkpoint, the shape in current model is torch.Size([4096, 4096]).\n\tsize mismatch for model.7.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([4096])."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "layer = EctLayer(\n",
    "    EctConfig(\n",
    "        num_thetas=config.layer.ect_size,\n",
    "        bump_steps=config.layer.ect_size,\n",
    "        normalized=True,\n",
    "        device=DEVICE,\n",
    "    ),\n",
    "    v=generate_directions(config.layer.ect_size,config.layer.dim, DEVICE),\n",
    ")\n",
    "\n",
    "# Load the encoder \n",
    "\n",
    "ect_encoder_litmodel = EctEncoder.load_from_checkpoint(\n",
    "    f\"./trained_models/ectencoder_topological.ckpt\",\n",
    "    layer=layer,\n",
    "    ect_size=config.layer.ect_size,\n",
    "    hidden_size=config.model.hidden_size,\n",
    "    num_pts=config.model.num_pts,\n",
    "    num_dims=config.model.num_dims,\n",
    "    learning_rate=config.model.learning_rate,\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an ECT and use VAE as autoencoder to recreate the ECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011\n",
      " 1012 1013 1014 1015 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009\n",
      " 2010 2011 2012 2013 2014 2015 3000 3001 3002 3003 3004 3005 3006 3007\n",
      " 3008 3009 3010 3011 3012 3013 3014 3015]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch_geometric.data import Batch\n",
    "# idxs = np.random.choice(list(range(4000)),64).tolist()\n",
    "idxs = np.hstack([\n",
    "    np.arange(0,16,1),\n",
    "    np.arange(1000,1016,1),\n",
    "    np.arange(2000,2016,1),\n",
    "    np.arange(3000,3016,1),\n",
    "])\n",
    "\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[65536, 3], y=[64], batch=[65536], ptr=[65])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = Batch.from_data_list([dm.test_ds[el] for el in idxs])\n",
    "\n",
    "print(features)\n",
    "features.to(DEVICE)\n",
    "ect = layer(features,features.batch).unsqueeze(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    decoded = ect_encoder_litmodel.model.forward(ect)\n",
    "\n",
    "import pyvista as pv\n",
    "\n",
    "pl = pv.Plotter(shape=(8, 8), window_size=[1600, 1600],border=False,polygon_smoothing=True)\n",
    "\n",
    "batch = features.x.cpu().detach().view(-1,1024,3).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c16200128e946dfb8472f30a04ed40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:54241/index.html?ui=P_0x23798e43b20_0&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row in range(8):\n",
    "    for col in range(8):\n",
    "        points = batch[8*row + col].reshape(-1, 3)\n",
    "        pl.subplot(row, col)\n",
    "        actor = pl.add_points(\n",
    "            points,\n",
    "            style=\"points\",\n",
    "            emissive=False,\n",
    "            show_scalar_bar=False,\n",
    "            render_points_as_spheres=True,\n",
    "            scalars=points[:, 2],\n",
    "            point_size=5,\n",
    "            ambient=0.2, \n",
    "            diffuse=0.8, \n",
    "            specular=0.8,\n",
    "            specular_power=40, \n",
    "            smooth_shading=True\n",
    "        )\n",
    "\n",
    "\n",
    "pl.background_color = \"w\"\n",
    "pl.link_views()\n",
    "pl.camera_position = \"yz\"\n",
    "pos = pl.camera.position\n",
    "pl.camera.position = (pos[0],pos[1],pos[2]+3)\n",
    "pl.camera.azimuth = -45\n",
    "pl.camera.elevation = 10\n",
    "\n",
    "# create a top down light\n",
    "light = pv.Light(position=(0, 0, 3), positional=True,\n",
    "                cone_angle=50, exponent=20, intensity=.2)\n",
    "pl.add_light(light)\n",
    "pl.camera.zoom(1.3)\n",
    "pl.screenshot(\"./figures/reconstructed_topological/reconstructed_pointcloud.png\",transparent_background=True,scale=2)\n",
    "pl.show()\n",
    "# path = pl.generate_orbital_path(n_points=64, shift=2, factor=3.0)\n",
    "# p0l.open_gif(\"./figures/reconstructed_topological/orbit_cloud.gif\")\n",
    "# pl.orbit_on_path(path, write_frames=True)\n",
    "# pl.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d2ffaa1db04eda8a00b51e8de242ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:54241/index.html?ui=P_0x2390c420e50_1&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "pl = pv.Plotter(shape=(8, 8), window_size=[1600, 1600],border=False,polygon_smoothing=True,off_screen=True)\n",
    "\n",
    "batch = decoded.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "for row in range(8):\n",
    "    for col in range(8):\n",
    "        points = batch[8*row + col].reshape(-1, 3)\n",
    "        pl.subplot(row, col)\n",
    "        actor = pl.add_points(\n",
    "            points,\n",
    "            style=\"points\",\n",
    "            emissive=False,\n",
    "            show_scalar_bar=False,\n",
    "            render_points_as_spheres=True,\n",
    "            scalars=points[:, 2],\n",
    "            point_size=5,\n",
    "            ambient=0.2, \n",
    "            diffuse=0.8, \n",
    "            specular=0.8,\n",
    "            specular_power=40, \n",
    "            smooth_shading=True\n",
    "        )\n",
    "\n",
    "\n",
    "pl.background_color = \"w\"\n",
    "pl.link_views()\n",
    "pl.camera_position = \"yz\"\n",
    "pos = pl.camera.position\n",
    "pl.camera.position = (pos[0],pos[1],pos[2]+3)\n",
    "pl.camera.azimuth = -45\n",
    "pl.camera.elevation = 10\n",
    "\n",
    "# create a top down light\n",
    "light = pv.Light(position=(0, 0, 3), positional=True,\n",
    "                cone_angle=50, exponent=20, intensity=.2)\n",
    "pl.add_light(light)\n",
    "pl.camera.zoom(1.3)\n",
    "pl.screenshot(\"./figures/reconstructed_topological/reconstructed_pointcloud.png\",transparent_background=True,scale=2)\n",
    "pl.show()\n",
    "path = pl.generate_orbital_path(n_points=64, shift=2, factor=3.0)\n",
    "pl.open_gif(\"./figures/reconstructed_topological/orbit_cloud.gif\")\n",
    "pl.orbit_on_path(path, write_frames=True)\n",
    "pl.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from VAE and reconstruct points "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
