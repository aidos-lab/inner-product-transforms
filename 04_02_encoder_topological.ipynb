{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "from datasets.topological import TopolocigalDataModule, TopologicalDataModuleConfig\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from models.vae_mnist import VanillaVAE\n",
    "from models.vae_modelnet import BaseModel as BaseVAE\n",
    "from models.ectencoder_modelnet import BaseModel as EctEncoder\n",
    "from datasets.modelnet import ModelNetDataModule, ModelNetDataModuleConfig\n",
    "from layers.ect import EctLayer, EctConfig\n",
    "\n",
    "from metrics.metrics import get_mse_metrics\n",
    "from metrics.accuracies import compute_mse_accuracies\n",
    "from metrics.loss import compute_mse_loss_fn\n",
    "from directions import generate_3d_directions\n",
    "\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "config = OmegaConf.load(\"./configs/config_encoder_topological.yaml\")\n",
    "\n",
    "dm = TopolocigalDataModule(TopologicalDataModuleConfig())\n",
    "\n",
    "print(len(dm.test_ds))\n",
    "\n",
    "# for batch in dm.test_dataloader():\n",
    "#     print(batch.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "layer = EctLayer(\n",
    "    EctConfig(\n",
    "        num_thetas=config.layer.ect_size,\n",
    "        bump_steps=config.layer.ect_size,\n",
    "        normalized=True,\n",
    "        device=DEVICE,\n",
    "    ),\n",
    "    v=generate_3d_directions(config.layer.ect_size, DEVICE),\n",
    ")\n",
    "\n",
    "# Load the encoder \n",
    "\n",
    "ect_encoder_litmodel = EctEncoder.load_from_checkpoint(\n",
    "    f\"./trained_models/ectencoder_topological.ckpt\",\n",
    "    layer=layer,\n",
    "    ect_size=config.layer.ect_size,\n",
    "    hidden_size=config.encodermodel.hidden_size,\n",
    "    num_pts=config.encodermodel.num_pts,\n",
    "    num_dims=config.encodermodel.num_dims,\n",
    "    learning_rate=config.encodermodel.learning_rate,\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an ECT and use VAE as autoencoder to recreate the ECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011\n",
      " 1012 1013 1014 1015 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009\n",
      " 2010 2011 2012 2013 2014 2015 3000 3001 3002 3003 3004 3005 3006 3007\n",
      " 3008 3009 3010 3011 3012 3013 3014 3015]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch_geometric.data import Batch\n",
    "# idxs = np.random.choice(list(range(4000)),64).tolist()\n",
    "idxs = np.hstack([\n",
    "    np.arange(0,16,1),\n",
    "    np.arange(1000,1016,1),\n",
    "    np.arange(2000,2016,1),\n",
    "    np.arange(3000,3016,1),\n",
    "])\n",
    "\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[65536, 3], y=[64], batch=[65536], ptr=[65])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = Batch.from_data_list([dm.test_ds[el] for el in idxs])\n",
    "\n",
    "print(features)\n",
    "features.to(DEVICE)\n",
    "ect = layer(features,features.batch).unsqueeze(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    decoded = ect_encoder_litmodel.model.forward(ect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb18a47aa9164f1582adbe99f8d2ff62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:54102/index.html?ui=P_0x1612d49a7a0_0&reconnect=auto\" class=\"pyvisâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "pl = pv.Plotter(shape=(8, 8), window_size=[1600, 1600],border=False,polygon_smoothing=True,off_screen=True)\n",
    "\n",
    "batch = decoded.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "for row in range(8):\n",
    "    for col in range(8):\n",
    "        points = batch[8*row + col].reshape(-1, 3)\n",
    "        pl.subplot(row, col)\n",
    "        actor = pl.add_points(\n",
    "            points,\n",
    "            style=\"points\",\n",
    "            emissive=False,\n",
    "            show_scalar_bar=False,\n",
    "            render_points_as_spheres=True,\n",
    "            scalars=points[:, 2],\n",
    "            point_size=5,\n",
    "            ambient=0.2, \n",
    "            diffuse=0.8, \n",
    "            specular=0.8,\n",
    "            specular_power=40, \n",
    "            smooth_shading=True\n",
    "        )\n",
    "\n",
    "\n",
    "pl.background_color = \"w\"\n",
    "pl.link_views()\n",
    "pl.camera_position = \"yz\"\n",
    "pos = pl.camera.position\n",
    "pl.camera.position = (pos[0],pos[1],pos[2]+3)\n",
    "pl.camera.azimuth = -45\n",
    "pl.camera.elevation = 10\n",
    "\n",
    "# create a top down light\n",
    "light = pv.Light(position=(0, 0, 3), positional=True,\n",
    "                cone_angle=50, exponent=20, intensity=.2)\n",
    "pl.add_light(light)\n",
    "pl.camera.zoom(1.3)\n",
    "pl.screenshot(\"./figures/reconstructed_topological/reconstructed_pointcloud.png\",transparent_background=True,scale=2)\n",
    "pl.show()\n",
    "path = pl.generate_orbital_path(n_points=64, shift=2, factor=3.0)\n",
    "pl.open_gif(\"./figures/reconstructed_topological/orbit_cloud.gif\")\n",
    "pl.orbit_on_path(path, write_frames=True)\n",
    "pl.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from VAE and reconstruct points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28474668,  0.43791795, -0.7230505 ],\n",
       "       [ 0.55132806,  0.33708215,  0.5813044 ],\n",
       "       [-0.42051172,  0.21979803,  0.7276568 ],\n",
       "       ...,\n",
       "       [ 0.06070867, -0.8520772 ,  0.07609331],\n",
       "       [ 0.38529867, -0.2652231 , -0.46679825],\n",
       "       [-0.2294608 , -0.23757058,  0.60195494]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = features.x.cpu().detach().numpy()\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m         points \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m         pl\u001b[38;5;241m.\u001b[39msubplot(row, col)\n\u001b[0;32m     12\u001b[0m         actor \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39madd_points(\n\u001b[0;32m     13\u001b[0m             points,\n\u001b[0;32m     14\u001b[0m             style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m             smooth_shading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     25\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "pl = pv.Plotter(shape=(8, 8), window_size=[1600, 1600],border=False,polygon_smoothing=True,off_screen=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for row in range(8):\n",
    "    for col in range(8):\n",
    "        points = features[8*row + col].x.reshape(-1, 3).numpy()\n",
    "        pl.subplot(row, col)\n",
    "        actor = pl.add_points(\n",
    "            points,\n",
    "            style=\"points\",\n",
    "            emissive=False,\n",
    "            show_scalar_bar=False,\n",
    "            render_points_as_spheres=True,\n",
    "            scalars=points[:, 2],\n",
    "            point_size=5,\n",
    "            ambient=0.2, \n",
    "            diffuse=0.8, \n",
    "            specular=0.8,\n",
    "            specular_power=40, \n",
    "            smooth_shading=True\n",
    "        )\n",
    "\n",
    "\n",
    "pl.background_color = \"w\"\n",
    "pl.link_views()\n",
    "pl.camera_position = \"yz\"\n",
    "pos = pl.camera.position\n",
    "pl.camera.position = (pos[0],pos[1],pos[2]+3)\n",
    "pl.camera.azimuth = -45\n",
    "pl.camera.elevation = 10\n",
    "\n",
    "# create a top down light\n",
    "light = pv.Light(position=(0, 0, 3), positional=True,\n",
    "                cone_angle=50, exponent=20, intensity=.2)\n",
    "pl.add_light(light)\n",
    "pl.camera.zoom(1.3)\n",
    "# pl.screenshot(\"./figures/reconstructed_topological/reconstructed_pointcloud.png\",transparent_background=True,scale=2)\n",
    "pl.show()\n",
    "# path = pl.generate_orbital_path(n_points=64, shift=2, factor=3.0)\n",
    "# pl.open_gif(\"./figures/reconstructed_topological/orbit_cloud.gif\")\n",
    "# pl.orbit_on_path(path, write_frames=True)\n",
    "pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
