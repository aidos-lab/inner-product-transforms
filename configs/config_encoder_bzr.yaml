data:
  samplepoints: 1024

encodermodel:
  hidden_size: 1024
  num_pts: 64
  num_dims: 3
  learning_rate: 0.001
  save_name: "ectencoder_bzr.ckpt" 

layer: 
  ect_size: 96

trainer:
  accelerator: auto
  max_epochs: 1000
  log_every_n_steps: 1

loggers: 
  project: "toporecon-dev"
  entity: aidos-labs
  save_dir: ./lightning_logs