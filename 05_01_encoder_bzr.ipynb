{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "from datasets.tu import TUBZRConfig, TUDataModule\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "from models.ectencoder_modelnet import BaseModel as EctEncoder\n",
    "from layers.ect import EctLayer, EctConfig\n",
    "\n",
    "from metrics.metrics import get_mse_metrics\n",
    "from metrics.accuracies import compute_mse_accuracies\n",
    "from metrics.loss import compute_mse_loss_fn\n",
    "from directions import generate_3d_directions\n",
    "\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "config = OmegaConf.load(\"./configs/config_encoder_bzr.yaml\")\n",
    "\n",
    "\n",
    "dm = TUDataModule(TUBZRConfig(use_node_attr=True))\n",
    "\n",
    "print(len(dm.test_ds))\n",
    "\n",
    "# for batch in dm.test_dataloader():\n",
    "#     print(batch.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "layer = EctLayer(\n",
    "    EctConfig(\n",
    "        num_thetas=config.layer.ect_size,\n",
    "        bump_steps=config.layer.ect_size,\n",
    "        normalized=True,\n",
    "        device=DEVICE,\n",
    "    ),\n",
    "    v=generate_3d_directions(config.layer.ect_size, DEVICE),\n",
    ")\n",
    "\n",
    "# Load the encoder \n",
    "\n",
    "ect_encoder_litmodel = EctEncoder.load_from_checkpoint(\n",
    "    f\"./trained_models/ectencoder_bzr.ckpt\",\n",
    "    layer=layer,\n",
    "    ect_size=config.layer.ect_size,\n",
    "    hidden_size=config.encodermodel.hidden_size,\n",
    "    num_pts=config.encodermodel.num_pts,\n",
    "    num_dims=config.encodermodel.num_dims,\n",
    "    learning_rate=config.encodermodel.learning_rate,\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an ECT and use VAE as autoencoder to recreate the ECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in dm.test_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features.to(DEVICE)\n",
    "ect = layer(features,features.batch).unsqueeze(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    decoded = ect_encoder_litmodel.model.forward(ect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9dbf1666c54a0884822b6f2bde615f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:59445/index.html?ui=P_0x12d382b40a0_0&reconnect=auto\" class=\"pyvisâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "\n",
    "pl = pv.Plotter(shape=(2, 8), window_size=[1600,400],border=False,polygon_smoothing=True,off_screen=True)\n",
    "\n",
    "batch = decoded.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "for col in range(8):\n",
    "    points = batch[col].reshape(-1, 3)\n",
    "    pl.subplot(0, col)\n",
    "    actor = pl.add_points(\n",
    "        features[col].x.cpu().detach().numpy(),\n",
    "        style=\"points\",\n",
    "        emissive=False,\n",
    "        show_scalar_bar=False,\n",
    "        render_points_as_spheres=True,\n",
    "        scalars=points[:, 2],\n",
    "        point_size=5,\n",
    "        ambient=0.2, \n",
    "        diffuse=0.8, \n",
    "        specular=0.8,\n",
    "        specular_power=40, \n",
    "        smooth_shading=True\n",
    "    )\n",
    "    pl.subplot(1, col)\n",
    "    actor = pl.add_points(\n",
    "        points,\n",
    "        style=\"points\",\n",
    "        emissive=False,\n",
    "        show_scalar_bar=False,\n",
    "        render_points_as_spheres=True,\n",
    "        scalars=points[:, 2],\n",
    "        point_size=5,\n",
    "        ambient=0.2, \n",
    "        diffuse=0.8, \n",
    "        specular=0.8,\n",
    "        specular_power=40, \n",
    "        smooth_shading=True\n",
    "    )\n",
    "\n",
    "\n",
    "pl.background_color = \"w\"\n",
    "pl.link_views()\n",
    "pl.camera_position = \"yz\"\n",
    "pos = pl.camera.position\n",
    "pl.camera.position = (pos[0],pos[1],pos[2]+3)\n",
    "pl.camera.azimuth = -45\n",
    "pl.camera.elevation = 10\n",
    "\n",
    "# create a top down light\n",
    "light = pv.Light(position=(0, 0, 3), positional=True,\n",
    "                cone_angle=50, exponent=20, intensity=.2)\n",
    "pl.add_light(light)\n",
    "pl.camera.zoom(1.3)\n",
    "# pl.screenshot(\"./figures/reconstructed_topological/reconstructed_pointcloud.png\",transparent_background=True,scale=2)\n",
    "pl.show()\n",
    "# path = pl.generate_orbital_path(n_points=64, shift=2, factor=3.0)\n",
    "# pl.open_gif(\"./figures/reconstructed_topological/orbit_cloud.gif\")\n",
    "# pl.orbit_on_path(path, write_frames=True)\n",
    "# pl.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from VAE and reconstruct points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.48657328,  0.4617581 ,  0.01141672],\n",
       "       [-0.528499  ,  0.21029627,  0.04302314],\n",
       "       [-0.33298758,  0.04703971,  0.07985406],\n",
       "       ...,\n",
       "       [ 0.24542014,  0.29359546, -0.03490202],\n",
       "       [-0.0442293 ,  0.0681807 , -0.03583009],\n",
       "       [-0.26892897, -0.51788855,  0.10893377]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = features.x.cpu().detach().numpy()\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m         points \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m         pl\u001b[38;5;241m.\u001b[39msubplot(row, col)\n\u001b[0;32m     12\u001b[0m         actor \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39madd_points(\n\u001b[0;32m     13\u001b[0m             points,\n\u001b[0;32m     14\u001b[0m             style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m             smooth_shading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     25\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "pl = pv.Plotter(shape=(8, 8), window_size=[1600, 1600],border=False,polygon_smoothing=True,off_screen=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for row in range(8):\n",
    "    for col in range(8):\n",
    "        points = features[8*row + col].x.reshape(-1, 3).numpy()\n",
    "        pl.subplot(row, col)\n",
    "        actor = pl.add_points(\n",
    "            points,\n",
    "            style=\"points\",\n",
    "            emissive=False,\n",
    "            show_scalar_bar=False,\n",
    "            render_points_as_spheres=True,\n",
    "            scalars=points[:, 2],\n",
    "            point_size=5,\n",
    "            ambient=0.2, \n",
    "            diffuse=0.8, \n",
    "            specular=0.8,\n",
    "            specular_power=40, \n",
    "            smooth_shading=True\n",
    "        )\n",
    "\n",
    "\n",
    "pl.background_color = \"w\"\n",
    "pl.link_views()\n",
    "pl.camera_position = \"yz\"\n",
    "pos = pl.camera.position\n",
    "pl.camera.position = (pos[0],pos[1],pos[2]+3)\n",
    "pl.camera.azimuth = -45\n",
    "pl.camera.elevation = 10\n",
    "\n",
    "# create a top down light\n",
    "light = pv.Light(position=(0, 0, 3), positional=True,\n",
    "                cone_angle=50, exponent=20, intensity=.2)\n",
    "pl.add_light(light)\n",
    "pl.camera.zoom(1.3)\n",
    "# pl.screenshot(\"./figures/reconstructed_topological/reconstructed_pointcloud.png\",transparent_background=True,scale=2)\n",
    "pl.show()\n",
    "# path = pl.generate_orbital_path(n_points=64, shift=2, factor=3.0)\n",
    "# pl.open_gif(\"./figures/reconstructed_topological/orbit_cloud.gif\")\n",
    "# pl.orbit_on_path(path, write_frames=True)\n",
    "pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
