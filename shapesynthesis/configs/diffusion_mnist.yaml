
# Global ect config, referenced in modelconfig.
ectconfig: &ref-ectconfig
  seed: 2024
  num_thetas: 64
  bump_steps: 128 
  r: 1.1
  ect_type: "points"
  num_features: 2
  normalized: True

data: 
  module: datasets.mnist
  root: "./data/mnistpointcloud"
  num_workers: 0
  batch_size: 64
  pin_memory: True
  drop_last: False
  ectconfig: *ref-ectconfig
  

modelconfig:
  module: models.diffusion
  num_pts: 128
  num_dims: 2
  learning_rate: .0001
  image_size: 128
  num_train_timesteps: 1000
  ectconfig: *ref-ectconfig
  

loggers: 
  project: toporecon-dev
  entity: aidos-labs
  save_dir: ./lightning_logs
  experiment_name: "diffusion_mnist"

trainer:
  accelerator: auto
  max_epochs: 50
  log_every_n_steps: 1
  save_dir: "trained_models" 
  model_name: "diffusion_mnist.ckpt" 
  

# @dataclass
# class TrainingConfig:
#     image_size = 128  # the generated image resolution
#     train_batch_size = 16
#     eval_batch_size = 16  # how many images to sample during evaluation
#     # num_epochs = 50
#     num_epochs = 1
#     gradient_accumulation_steps = 1
#     learning_rate = 1e-4
#     lr_warmup_steps = 500
#     save_image_epochs = 10
#     save_model_epochs = 30
#     mixed_precision = "fp16"  # `no` for float32, `fp16` for automatic mixed precision
#     output_dir = "ddpm-butterflies-128"  # the model name locally and on the HF Hub

#     push_to_hub = False  # whether to upload the saved model to the HF Hub
#     hub_private_repo = False
#     overwrite_output_dir = True  # overwrite the old model when re-running the notebook
#     seed = 0
#     dataset_name = "huggan/smithsonian_butterflies_subset"